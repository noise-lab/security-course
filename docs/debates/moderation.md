## Automated Content Moderation

### Resolution

**Automated content moderation is more harmful than beneficial for protecting free speech and promoting healthy online discourse.**

The debate will be "Oxford Style" and follow [this format](format.md).

### Resources

Here are some resources and questions to help guide and nuance the debate:

**Questions**

1. What are the scalability challenges of human content moderation vs. automated systems?
2. How accurate are automated systems at detecting context, sarcasm, and nuanced speech?
3. What are the consequences of false positives (over-moderation) vs. false negatives (under-moderation)?
4. Should platforms be transparent about their automated moderation algorithms?
5. How do automated systems handle cultural and linguistic differences across global platforms?
6. What role should human oversight play in automated content moderation decisions?

**Readings**

- [Automated Content Moderation: Flagging and Filtering](https://www.eff.org/issues/content-moderation)
- [The Impact of AI on Free Speech](https://www.brookings.edu/research/the-impact-of-ai-on-free-speech/)
- [Automated Content Moderation: Benefits and Challenges](https://www.cfr.org/report/automated-content-moderation-benefits-and-challenges)
- [Platform Regulation and Automated Content Moderation](https://www.oxfordmartin.ox.ac.uk/news/automated-content-moderation/)
- [Challenges of Automated Content Moderation in Social Media](https://ec.europa.eu/digital-strategy/news/challenges-automated-content-moderation-social-media_en)
- [Algorithmic Content Moderation: Risks and Impacts](https://datasociety.net/wp-content/uploads/2019/04/Algorithmic-Content-Moderation-Full-Report-Digital.pdf)
